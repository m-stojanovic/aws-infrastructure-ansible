- hosts: localhost
  gather_facts: yes
  vars_files:
    - keys.yml
  vars:
    aws_tags:
    Name: "{{ site_name }}"
    Application: "{{ site_name }}"
    Environment: "Development"
    Costcenter: "1xxxxxxx3"
    Division: "My"
    Consumer: "petr.ruzicka@gmail.com"
  tasks:
    # Get AWS ami image id #
    - name: Get the AMI image id
      ec2_ami_info:
        aws_access_key: "{{ AWS_ACCESS_KEY_ID }}"
        aws_secret_key: "{{ AWS_SECRET_ACCESS_KEY }}"
        region: "{{ AWS_REGION }}"
        filters:
          name: "amzn2-ami-hvm-*-x86_64-gp2"
      register: ami_find

    - name: Sort the latest AMI
      set_fact:
        latest_ami: "{{ ami_find.images | sort(attribute='creation_date') | last }}"

    - name: Debug the AMI image
      debug:
        var: latest_ami

    # Create AWS keypair #
    - name: Create aws private keypair
      ec2_key:
        aws_access_key: "{{ AWS_ACCESS_KEY_ID }}"
        aws_secret_key: "{{ AWS_SECRET_ACCESS_KEY }}"
        region: "{{ AWS_REGION }}"
        name: carnegie1
        key_material: "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC5IkRNJQtrROT8pjKJeoA8lF7wQ6wfIcj4xxE/nRc19xTebwOMlYfpfTRfSk65FjFkf0xLuDTpa8r/dA+tmkMkj3oCFR+UKCyTFyhxWbRvVzaRckk+ph8BcENNMHd8uAAukBnHlJiPwI1+BCaSNR1LhUGTRBiiTJMK8dxfBHnfGfSm3s7j8yVQbYcGk8GC8cYk5m6ZfF3UBeD0/P6mdx0eIKCGkfk2yWFHOK+BAJgwC0GNPChxHY07ywBk7+X7fIj3+ldyXIH+vtBkx6nWXJ1nw9zz1mFCa9QziybsglcOS//zKxmQ4lAVOcul4xpiY6fODHtXKS2RB1dm0ADKuDUb CarnegieKey"

    # Create EC2 octopus instance #
    - name: Change octopus instance state by tag
      ec2:
        aws_access_key: "{{ AWS_ACCESS_KEY_ID }}"
        aws_secret_key: "{{ AWS_SECRET_ACCESS_KEY }}"
        region: "{{ AWS_REGION }}"
        key_name: carnegie1
        instance_type: "{{ i_type }}"
        image: "{{ latest_ami.image_id }}"
        wait: yes
        wait_timeout: 500
        #assign_public_ip: no
        #vpc_subnet_id: "{{ public_subnet_1.subnet.id }}"
        volumes:
          - device_name: /dev/xvda
            volume_type: gp2
            volume_size: 20
            delete_on_termination: yes
            tags:
              Name: "{{ name }}-{{ dev_environment }}-volume"
              user:client: "{{ name }}"
              user:Environment: "{{ dev_environment }}"
        instance_tags:
          Name: "{{ name }}-{{ dev_environment }}-all"
          user:client: "{{ name }}"
          user:Environment: "{{ dev_environment }}"
        exact_count: 1
        count_tag:
          Name: "{{ name }}-{{ dev_environment }}-all"
          user:client: "{{ name }}"
          user:Environment: "{{ dev_environment }}"
      register: octopus_var

    # - name: Debug {{ name }}-{{ dev_environment }}-all result
    #   debug:
    #     var: octopus_var

    # Gather EC2 Instance Facts #
    - name: Gather EC2 Facts
      ec2_instance_info:
        filters:
          "tag:user:client": "{{ name }}"
      register: ec2_facts

    - name: Debug EC2 Facts
      debug:
        var: ec2_facts
    # # Create EC2 Octopus Volume #
    # - name: Create volume for octopus instance
    #   ec2_vol:
    #     aws_access_key: "{{ AWS_ACCESS_KEY_ID }}"
    #     aws_secret_key: "{{ AWS_SECRET_ACCESS_KEY }}"
    #     region: "{{ AWS_REGION }}"
    #     instance: "{{ item.instance_id }}"
    #     volume_size: 20
    #     device_name: /dev/xvda
    #     volume_type: gp2
    #     tags:
    #       Name: "{{ name }}-{{ dev_environment }}-volume"
    #       user:client: "{{ name }}"
    #       user:Environment: "{{ dev_environment }}"
    #   with_items: "{{ ec2_facts.instances }}"
    #   register: volumeCreate
    # - name: Debug volumeCreate Facts
    #   debug:
    #     var: volumeCreate
    # - name: Gather EC2 volume Facts
    #   ec2_vol_info:
    #     filters:
    #       "tag:user:client": "{{ name }}"
    #   register: vol_facts
    # - name: Debug vol Facts
    #   debug:
    #     var: vol_facts
    # # Gather EC2 volume facts #
    # - name: Gather EC2 volume Facts
    #   ec2_vol:
    #     aws_access_key: "{{ AWS_ACCESS_KEY_ID }}"
    #     aws_secret_key: "{{ AWS_SECRET_ACCESS_KEY }}"
    #     region: "{{ AWS_REGION }}"
    #     instance: "{{ item.instance_id }}"
    #     state: list
    #   with_items: "{{ ec2_facts.instances }}"
    #   register: ec2_instances_volumes
    #   loop_control:
    #     label: "{{ item }}"
    #     #filters:
    #     #  attachment.instance-id: "{{ item.instance_id }}"
    #   #with_items: "{{ ec2_facts.instances }}"
    #   #register: vol_facts
    # - name: Debug vol Facts
    #   debug:
    #     var: ec2_instances_volumes
    # - name: Tag volumes
    #   ec2_tag:
    #     aws_access_key: "{{ AWS_ACCESS_KEY_ID }}"
    #     aws_secret_key: "{{ AWS_SECRET_ACCESS_KEY }}"
    #     region: "{{ AWS_REGION }}"
    #     resource: "{{ item.1.id }}"
    #     tags: "{{ aws_tags | combine({'Instance': item.1.attachment_set.instance_id}, {'Device': item.1.attachment_set.device}) }}"
    #   with_subelements:
    #     - "{{ ec2_instances_volumes.results }}"
    #     - volumes
    #   loop_control:
    #     label: "{{ item.1.id }} - {{ item.1.attachment_set.device }}"
    # - name: Wait for SSH to come up
    #   wait_for: host={{ item.private_ip }} port=22 delay=60 timeout=320 state=started
    #   with_items: "{{ ec2_facts.instances }}"
    #   loop_control:
    #     label: "{{ item.id }} - {{ item.private_ip }}"
    # - name: Gather EC2 volume Facts
    #   ec2_vol_info:
    #   register: vol_facts2
    # - name: Debug vol Facts
    #   debug:
    #     var: vol_facts2
    # - name: Set EC2 Volume Fact
    #   set_fact:
    #     vol_id: "{{ item.id }}" # | sort(attribute='create_time') | last }}"
    #   with_items: "{{ vol_facts2.volumes }}"
    # - name: Debug new Fact
    #   debug:
    #     var: vol_id
    # - name: Set EC2 Volume Fact
    #   set_fact:
    #     #vol_id: "{{ item.id }}"
    #     vol_id: "{{ block_device_mappings.ebs }}" # | sort(attribute='create_time') | last }}"
    #   with_items: "{{ ec2_facts.instances }}"
    # - name: Debug new Fact
    #   debug:
    #     var: vol_id
  # Delete volumes #
  #- name: Delete EC2 Instances volumes
  #  ec2_vol:
